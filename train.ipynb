{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T13:31:18.757441861Z",
     "start_time": "2023-08-16T13:31:18.641350171Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T12:31:27.519590738Z",
     "start_time": "2023-08-16T12:28:29.743305416Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the path to the main folder containing real and fake subfolders\n",
    "main_folder = '/media/real/data/dataset'\n",
    "\n",
    "# Set the paths to the train and test folders\n",
    "train_folder = 'dataset/train'\n",
    "test_folder = 'dataset/test'\n",
    "\n",
    "# Set the train/test split ratio\n",
    "train_ratio = 0.8\n",
    "\n",
    "# Create train and test folders if they don't exist\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "balance = True\n",
    "\n",
    "subfolders = ['real', 'fake', 'blurred', 'low_quality', 'distorted']\n",
    "\n",
    "\n",
    "# Function to copy files from source to destination folder\n",
    "def copy_files(file_list, src_folder, dest_folder):\n",
    "    for file_name in file_list:\n",
    "\n",
    "        #check if the image file is valid\n",
    "        try:\n",
    "            img = Image.open(os.path.join(src_folder, file_name)) # open the image file\n",
    "            img.verify() # verify that it is, in fact an image\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print('Bad file:', file_name) # print out the names of corrupt files\n",
    "            continue\n",
    "        src_path = os.path.join(src_folder, file_name)\n",
    "        dest_path = os.path.join(dest_folder, file_name)\n",
    "        shutil.copy(src_path, dest_path)\n",
    "\n",
    "# Iterate through the subfolders in the main folder\n",
    "for subfolder in subfolders:\n",
    "    subfolder_path = os.path.join(main_folder, subfolder)\n",
    "    files = os.listdir(subfolder_path)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    # Split the files into train and test sets\n",
    "    train_files = files[:int(train_ratio * len(files))]\n",
    "    test_files = files[int(train_ratio * len(files)):]\n",
    "\n",
    "    # Copy train files to the train folder\n",
    "    train_subfolder_path = os.path.join(train_folder, subfolder)\n",
    "    os.makedirs(train_subfolder_path, exist_ok=True)\n",
    "    copy_files(train_files, subfolder_path, train_subfolder_path)\n",
    "\n",
    "    # Copy test files to the test folder\n",
    "    test_subfolder_path = os.path.join(test_folder, subfolder)\n",
    "    os.makedirs(test_subfolder_path, exist_ok=True)\n",
    "    copy_files(test_files, subfolder_path, test_subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T12:31:36.946173417Z",
     "start_time": "2023-08-16T12:31:34.263444184Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load ResNet50 without the top classification layers\n",
    "# Load InceptionV3 without the top classification layers\n",
    "base_model = InceptionV3(input_shape=(299, 299, 3), include_top=False, weights='imagenet')\n",
    "#base_model = ResNet50(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Define the number of layers to unfreeze\n",
    "num_layers_to_unfreeze = 150  # For example, unfreeze the first 100 layers\n",
    "\n",
    "# Unfreeze layers starting from the specified index\n",
    "for layer in base_model.layers[:num_layers_to_unfreeze]:\n",
    "    layer.trainable = True\n",
    "for layer in base_model.layers[num_layers_to_unfreeze:]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom classification layers on top of the base model\n",
    "num_classes = 5  # Number of classes: real, fake, blurred, low_quality, distorted\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')  # Use softmax activation for multi-class\n",
    "])\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True, expand_nested=True)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, concatenate, GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "def inception_module(x, filters):\n",
    "    # 1x1 Conv\n",
    "    conv1 = Conv2D(filters=filters[0], kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
    "\n",
    "    # 1x1 Conv followed by 3x3 Conv\n",
    "    conv3 = Conv2D(filters=filters[1], kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
    "    conv3 = Conv2D(filters=filters[2], kernel_size=(3, 3), padding='same', activation='relu')(conv3)\n",
    "\n",
    "    # 1x1 Conv followed by 5x5 Conv\n",
    "    conv5 = Conv2D(filters=filters[3], kernel_size=(1, 1), padding='same', activation='relu')(x)\n",
    "    conv5 = Conv2D(filters=filters[4], kernel_size=(5, 5), padding='same', activation='relu')(conv5)\n",
    "\n",
    "    # 3x3 MaxPooling followed by 1x1 Conv\n",
    "    pool = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n",
    "    pool = Conv2D(filters=filters[5], kernel_size=(1, 1), padding='same', activation='relu')(pool)\n",
    "\n",
    "    # Concatenate all the branches\n",
    "    output = concatenate([conv1, conv3, conv5, pool], axis=-1)\n",
    "    return output\n",
    "\n",
    "# Create the model\n",
    "input_layer = Input(shape=(480, 640, 3))\n",
    "\n",
    "x = Conv2D(filters=64, kernel_size=(7, 7), padding='same', strides=(2, 2), activation='relu')(input_layer)\n",
    "x = MaxPooling2D(pool_size=(3, 3), padding='same', strides=(2, 2))(x)\n",
    "\n",
    "x = inception_module(x, filters=[64, 128, 128, 32, 32, 32])\n",
    "x = inception_module(x, filters=[128, 256, 256, 64, 64, 64])\n",
    "\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(5, activation='softmax')(x)  # Assuming 5 classes as in your previous example\n",
    "\n",
    "custom_model = tf.keras.Model(inputs=input_layer, outputs=x)\n",
    "custom_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "plot_model(custom_model, to_file='./model_architecture.png', show_shapes=True, show_layer_names=True, expand_nested=True)\n",
    "\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T12:32:18.025506588Z",
     "start_time": "2023-08-16T12:32:17.351407858Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify the paths to the dataset folders\n",
    "train_data_dir = 'dataset/train'\n",
    "test_data_dir = 'dataset/test'\n",
    "\n",
    "# Set the image size and batch size\n",
    "image_size = (480, 640)\n",
    "#image_size = (299, 299)\n",
    "batch_size = 16\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# List of class names\n",
    "class_names = ['real', 'fake', 'blurred', 'low_quality', 'distorted']\n",
    "\n",
    "# Load and prepare the training data\n",
    "train_data = data_generator.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',  # Use 'categorical' for multi-class classification\n",
    "    classes=class_names,       # List of class names\n",
    "    shuffle=True\n",
    ")\n",
    "# Load and prepare the testing data\n",
    "test_data = data_generator.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    classes=class_names,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:30:57.535516970Z",
     "start_time": "2023-08-16T13:31:24.886674108Z"
    }
   },
   "outputs": [],
   "source": [
    " # Define the number of training and testing steps per epoch\n",
    "train_steps_per_epoch = train_data.samples // batch_size\n",
    "test_steps_per_epoch = test_data.samples // batch_size\n",
    "# Define the paths for saving the checkpoints and the best model\n",
    "checkpoint_path = \"checkpoint/model_checkpoint\"\n",
    "best_model_path = \"best_model/best_model_savedmodel\"\n",
    "\n",
    "# Ensure the checkpoint directory exists\n",
    "os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
    "\n",
    "# Create the ModelCheckpoint callback to save the model at the end of each epoch\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    monitor='val_loss',  # Save based on validation loss\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    save_weights_only=False,  # Save the entire model\n",
    "    mode='min',  # Minimize validation loss\n",
    "    verbose=1\n",
    ")\n",
    "# early_stopping_callback = EarlyStopping(\n",
    "#     monitor='val_loss',\n",
    "#     patience=5,  # Number of epochs with no improvement before stopping\n",
    "#     mode='min',  # Minimize validation loss\n",
    "#     verbose=1\n",
    "# )\n",
    "# Create the ReduceLROnPlateau callback\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    factor=0.5,           # Reduce learning rate by half\n",
    "    patience=3,           # Number of epochs with no improvement before reducing LR\n",
    "    min_lr=1e-6,          # Minimum learning rate\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history=custom_model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_steps_per_epoch,\n",
    "    epochs=50,\n",
    "    validation_data=test_data,\n",
    "    validation_steps=test_steps_per_epoch,\n",
    "    callbacks=[checkpoint_callback, reduce_lr_callback]\n",
    ")\n",
    "\n",
    "custom_model_best = tf.keras.models.load_model(checkpoint_path)  # Load the best model from the checkpoint\n",
    "\n",
    "\n",
    "custom_model_best.save('best_model(480x640).savedmodel')\n",
    "custom_model.save('last_model(480x640).savedmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:32:38.394925369Z",
     "start_time": "2023-08-16T14:32:05.937683908Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "best_model = tf.keras.models.load_model(checkpoint_path)  # Load the best model from the checkpoint\n",
    "best_model.save(best_model_path)\n",
    "\n",
    "best_model.save('best_model(480x640).savedmodel')\n",
    "model.save('last_model.savedmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T11:54:34.813299054Z",
     "start_time": "2023-08-15T11:54:34.687298715Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " #last_layer_name \n",
    "print(model.layers[-1].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T11:46:18.357117698Z",
     "start_time": "2023-08-15T11:46:18.120115952Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation accuracy over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:33:16.795904687Z",
     "start_time": "2023-08-16T14:32:38.402119154Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_loss, val_acc = best_model.evaluate(test_data)\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:33:53.251731685Z",
     "start_time": "2023-08-16T14:33:16.795202441Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pre= best_model.predict(test_data)\n",
    "y_pred = np.argmax(y_pre, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_data.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['real', 'fake', 'blurred', 'low_quality', 'distorted']\n",
    "print(classification_report(test_data.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T14:33:54.887461603Z",
     "start_time": "2023-08-16T14:33:54.872223112Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#round y_pre first prediction\n",
    "y_pre_round = np.round(y_pre)\n",
    "print(y_pre_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T03:27:55.958249043Z",
     "start_time": "2023-08-15T03:27:25.029771769Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Define the paths for the validation data\n",
    "validation_folder = '/home/real/datasets/validation'\n",
    "real_folder = os.path.join(validation_folder, 'real')\n",
    "fake_folder = os.path.join(validation_folder, 'fake')\n",
    "\n",
    "\n",
    "best_model_path = \"best_model/best_model_savedmodel\"\n",
    "best_model = tf.keras.models.load_model(best_model_path)\n",
    "# Load the model\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image_path, image_size):\n",
    "    img = load_img(image_path, target_size=image_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Function to predict on the validation data\n",
    "def predict_on_validation_data(validation_folder, image_size, model):\n",
    "    real_images = []\n",
    "    fake_images = []\n",
    "\n",
    "    for image_file in os.listdir(real_folder):\n",
    "        image_path = os.path.join(real_folder, image_file)\n",
    "        real_images.append(preprocess_image(image_path, image_size))\n",
    "\n",
    "    for image_file in os.listdir(fake_folder):\n",
    "        image_path = os.path.join(fake_folder, image_file)\n",
    "        fake_images.append(preprocess_image(image_path, image_size))\n",
    "\n",
    "    real_images = np.vstack(real_images)\n",
    "    fake_images = np.vstack(fake_images)\n",
    "\n",
    "    real_predictions = model.predict(real_images)\n",
    "    fake_predictions = model.predict(fake_images)\n",
    "\n",
    "    return real_predictions, fake_predictions\n",
    "\n",
    "# Set the image size for the model\n",
    "# image_size = (640, 480)  # Replace with the appropriate image size based on your model's input requirements\n",
    "image_size = (299, 299)\n",
    "def plot_images_and_predictions(images, predictions, title):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    for i in range(len(images)):\n",
    "        # plt.subplot( 2, len(images)//2, i+1)\n",
    "        plt.subplot( len(images)//2, 4, i+1)\n",
    "        # image in rgb format\n",
    "        # plt.imshow(mpimg.imread(images[i]))\n",
    "        plt.imshow(cv2.cvtColor(cv2.imread(images[i]), cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f'Prediction: {predictions[i][0]:.2f}')\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.show()\n",
    "# Run validation on the data\n",
    "real_predictions, fake_predictions = predict_on_validation_data(validation_folder, image_size, model)\n",
    "\n",
    "# Assuming the model is a binary classifier, you can calculate the accuracy for both classes\n",
    "real_accuracy = np.mean(real_predictions > 0.5)\n",
    "fake_accuracy = np.mean(fake_predictions < 0.5)\n",
    "\n",
    "print(\"Real Accuracy:\", real_accuracy)\n",
    "print(\"Fake Accuracy:\", fake_accuracy)\n",
    "# Get the file paths for the real and fake images\n",
    "real_images_paths = [os.path.join(real_folder, image_file) for image_file in os.listdir(real_folder)]\n",
    "fake_images_paths = [os.path.join(fake_folder, image_file) for image_file in os.listdir(fake_folder)]\n",
    "\n",
    "# Show images and associated predictions in a grid\n",
    "plot_images_and_predictions(real_images_paths[:10], real_predictions[:10], title=\"Real Images and Predictions\")\n",
    "plot_images_and_predictions(fake_images_paths[:30], fake_predictions[:30], title=\"Fake Images and Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T03:28:04.725159859Z",
     "start_time": "2023-08-15T03:28:04.722263862Z"
    }
   },
   "outputs": [],
   "source": [
    "# get first layer name\n",
    "print(model.layers[0].name)\n",
    "\n",
    "# get last layer name\n",
    "print(model.layers[-1].name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T03:25:24.768340517Z",
     "start_time": "2023-08-15T03:25:24.666228650Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define your image size\n",
    "image_size = (224, 224)  # Adjust this to your desired image size\n",
    "\n",
    "# Define the path to the main folder containing 'real' and 'fake' subfolders\n",
    "data_dir = 'path/to/dataset'\n",
    "\n",
    "# Define the batch size for the data generator\n",
    "batch_size = 32\n",
    "\n",
    "# Use ImageDataGenerator for data loading and augmentation\n",
    "datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)  # Normalize pixel values and split for validation\n",
    "\n",
    "# Load the data from the main folder, split into training and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "# Evaluate the model on the validation set\n",
    "validation_loss, validation_accuracy = model.evaluate(validation_generator)\n",
    "print(\"Validation Loss:\", validation_loss)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T03:47:13.465767651Z",
     "start_time": "2023-08-15T03:47:13.341704238Z"
    }
   },
   "outputs": [],
   "source": [
    "#save model;\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-30T10:39:55.868418Z",
     "start_time": "2023-07-30T10:39:53.287859Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load model;\n",
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T09:56:19.716237257Z",
     "start_time": "2023-08-12T09:56:19.650217026Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-31T12:39:06.255065Z",
     "start_time": "2023-07-31T12:39:06.133639Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run model on a single image\n",
    "fake_image = 'dataset/test/real/0c73777d1a944251869584b56d0997ef.jpg'\n",
    "\n",
    "fake_image = tf.keras.preprocessing.image.load_img(\n",
    "    fake_image, target_size=image_size\n",
    ")\n",
    "\n",
    "fake_image = tf.keras.preprocessing.image.img_to_array(fake_image)\n",
    "fake_image = np.expand_dims(fake_image, axis=0)\n",
    "fake_image = fake_image / 255\n",
    "\n",
    "\n",
    "prediction = model.predict(fake_image)\n",
    "print(\"Prediction:\", prediction)\n",
    "print(\"predicted class:\", \"fake\" if prediction < 0.5 else \"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save model tensortrt model for inference\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.compiler.tensorrt import trt_convert as trt\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "# Convert the model\n",
    "converter = trt.TrtGraphConverterV2(\n",
    "    input_saved_model_dir='model.h5',\n",
    "    conversion_params=trt.DEFAULT_TRT_CONVERSION_PARAMS)\n",
    "converter.convert()\n",
    "converter.save(output_saved_model_dir='model_trt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-12T09:57:58.668126429Z",
     "start_time": "2023-08-12T09:57:49.484245530Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save model tensorflow saved model format\n",
    "model.save('model.savedmodel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T14:18:51.393176Z",
     "start_time": "2023-08-03T14:18:51.349390Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get first and last layer of the model name and s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
